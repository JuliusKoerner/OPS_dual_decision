{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = '/nfs/students/koerner/Datasets/coco/annotations/instances_val2017_all_categories_with_longtail.json'\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    file = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"categories\"].__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create panoptic gt file for the with longtail annotations for full val and _100\n",
    "\n",
    "For that set the anomaly classes to a specific value, the models should predict this value for the anomalies\n",
    "\n",
    "Take the images from the instance json file and create the panoptic ground truth for exactly these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_json = \"/nfs/students/koerner/Datasets/Coco2/annotations/instances_val2017_with_longtail.json\"\n",
    "gt_json = \"/nfs/students/koerner/Datasets/Coco2/annotations/panoptic_val2017.json\"\n",
    "longtail_names = [e.replace('\\n', '') for e in open('datasets/unknown/unknown_K20_longtail.txt', 'r').readlines()]\n",
    "import json\n",
    "\n",
    "with open(instance_json, \"r\") as f:\n",
    "    instance_json = json.load(f)\n",
    "with open(gt_json, \"r\") as f:\n",
    "    gt_json = json.load(f)\n",
    "instance_images = sorted(set([ann[\"image_id\"] for ann in instance_json[\"annotations\"]]))\n",
    "\n",
    "from detectron2.data.datasets.builtin_meta import COCO_CATEGORIES\n",
    "\n",
    "longtail_ids = [c[\"id\"] for c in COCO_CATEGORIES if c[\"name\"] in longtail_names]\n",
    "assert longtail_ids.__len__() == longtail_names.__len__()\n",
    "gt_json.keys()\n",
    "longtail_id = 254\n",
    "counter = 0\n",
    "for anno in gt_json[\"annotations\"]:\n",
    "# if image_id ininstance_images oder so\n",
    "    if anno[\"image_id\"] not in instance_images:\n",
    "        continue\n",
    "    segments = anno[\"segments_info\"]\n",
    "    \n",
    "\n",
    "    \n",
    "    for seg in segments:\n",
    "        if seg[\"category_id\"] in longtail_ids:\n",
    "            seg[\"category_id\"] = longtail_id\n",
    "            counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['info', 'licenses', 'images', 'annotations', 'categories']),\n",
       " dict_keys(['info', 'licenses', 'images', 'annotations', 'categories']))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_json.keys(), gt_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the categories for the with files correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_json = \"/nfs/students/koerner/Datasets/Coco2/annotations/instances_val2017_with_longtail.json\"\n",
    "instance_100_json = \"/nfs/students/koerner/Datasets/Coco2/annotations/instances_val2017_100_with_longtail.json\"\n",
    "instance_without = \"/nfs/students/koerner/Datasets/Coco2/annotations/instances_val2017_without_longtail.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(instance_without, \"r\") as f:\n",
    "    without = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(instance_json, \"r\") as f:\n",
    "    instance = json.load(f)\n",
    "instance[\"categories\"] = without[\"categories\"]\n",
    "with open(instance_json, \"w\") as f:\n",
    "    json.dump(instance,f)\n",
    "\n",
    "with open(instance_100_json, \"r\") as f:\n",
    "    instance = json.load(f)\n",
    "instance[\"categories\"] = without[\"categories\"]\n",
    "with open(instance_100_json, \"w\") as f:\n",
    "    json.dump(instance,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check json files for dataloader and gt for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_json = \"/nfs/students/koerner/Datasets/Coco2/annotations/instances_val2017_with_longtail.json\"\n",
    "gt_json = \"/nfs/students/koerner/Datasets/Coco2/annotations/panoptic_val2017.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(loader_json, \"r\") as f:\n",
    "    loader_json = json.load(f)\n",
    "with open(gt_json, \"r\") as f:\n",
    "    gt_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_images = sorted(set([ann[\"image_id\"] for ann in loader_json[\"annotations\"]]))\n",
    "gt_json_images = sorted(set([ann[\"image_id\"] for ann in gt_json[\"annotations\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in = []\n",
    "for im in loader_images:\n",
    "    if im not in gt_json_images:\n",
    "        not_in.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_images.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_in.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/nfs/students/koerner/Datasets/Coco2/annotations/instances_val2017_100_without_longtail.json\"\n",
    "with open(path, \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data[\"categories\"].__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instance = \"/nfs/students/koerner/Datasets/coco/annotations/instances_val2017.json\"\n",
    "panoptic = \"/nfs/students/koerner/Datasets/coco/annotations/panoptic_val2017_100.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(instance, \"r\") as f:\n",
    "    instance = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(panoptic, \"r\") as f:\n",
    "    panoptic = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['info', 'licenses', 'images', 'annotations', 'categories']),\n",
       " dict_keys(['info', 'licenses', 'images', 'annotations', 'categories']))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.keys(), panoptic.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segments_info': [{'id': 1447707,\n",
       "   'category_id': 1,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [502, 78, 138, 343],\n",
       "   'area': 22793},\n",
       "  {'id': 4011573,\n",
       "   'category_id': 1,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [0, 209, 24, 81],\n",
       "   'area': 1605},\n",
       "  {'id': 1116963,\n",
       "   'category_id': 1,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [402, 205, 66, 88],\n",
       "   'area': 3893},\n",
       "  {'id': 1906457,\n",
       "   'category_id': 1,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [27, 213, 50, 70],\n",
       "   'area': 1808},\n",
       "  {'id': 8685451,\n",
       "   'category_id': 9,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [292, 87, 121, 56],\n",
       "   'area': 1831},\n",
       "  {'id': 5588540,\n",
       "   'category_id': 9,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [125, 125, 139, 17],\n",
       "   'area': 1713},\n",
       "  {'id': 4404785,\n",
       "   'category_id': 9,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [0, 130, 105, 15],\n",
       "   'area': 1208},\n",
       "  {'id': 5985877,\n",
       "   'category_id': 16,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [193, 225, 74, 33],\n",
       "   'area': 1038},\n",
       "  {'id': 1183244,\n",
       "   'category_id': 27,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [22, 231, 22, 52],\n",
       "   'area': 664},\n",
       "  {'id': 395290,\n",
       "   'category_id': 31,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [492, 198, 104, 227],\n",
       "   'area': 10016},\n",
       "  {'id': 2433830,\n",
       "   'category_id': 77,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [529, 181, 30, 18],\n",
       "   'area': 392},\n",
       "  {'id': 3027511,\n",
       "   'category_id': 95,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [0, 0, 640, 174],\n",
       "   'area': 58519},\n",
       "  {'id': 2500390,\n",
       "   'category_id': 125,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [64, 248, 449, 58],\n",
       "   'area': 9876},\n",
       "  {'id': 11645618,\n",
       "   'category_id': 148,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [0, 130, 640, 144],\n",
       "   'area': 50922},\n",
       "  {'id': 4607051,\n",
       "   'category_id': 184,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [0, 53, 358, 72],\n",
       "   'area': 13629},\n",
       "  {'id': 15395563,\n",
       "   'category_id': 187,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [0, 28, 138, 45],\n",
       "   'area': 3475},\n",
       "  {'id': 3288623,\n",
       "   'category_id': 191,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [0, 272, 640, 155],\n",
       "   'area': 64972},\n",
       "  {'id': 5853260,\n",
       "   'category_id': 197,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [0, 39, 404, 111],\n",
       "   'area': 11231},\n",
       "  {'id': 3682863,\n",
       "   'category_id': 198,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [298, 238, 111, 65],\n",
       "   'area': 4082},\n",
       "  {'id': 2697775,\n",
       "   'category_id': 199,\n",
       "   'iscrowd': 0,\n",
       "   'bbox': [387, 268, 157, 59],\n",
       "   'area': 4555}],\n",
       " 'file_name': '000000001268.png',\n",
       " 'image_id': 1268}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panoptic[\"annotations\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': [[304.09,\n",
       "   266.18,\n",
       "   308.95,\n",
       "   263.56,\n",
       "   313.06,\n",
       "   262.81,\n",
       "   318.3,\n",
       "   262.81,\n",
       "   322.04,\n",
       "   262.81,\n",
       "   336.25,\n",
       "   264.68,\n",
       "   338.87,\n",
       "   264.68,\n",
       "   344.85,\n",
       "   259.07,\n",
       "   353.83,\n",
       "   252.34,\n",
       "   352.7,\n",
       "   258.32,\n",
       "   344.1,\n",
       "   269.17,\n",
       "   352.33,\n",
       "   274.4,\n",
       "   357.94,\n",
       "   281.88,\n",
       "   357.94,\n",
       "   293.1,\n",
       "   356.07,\n",
       "   300.58,\n",
       "   356.44,\n",
       "   308.06,\n",
       "   354.57,\n",
       "   319.28,\n",
       "   353.45,\n",
       "   326.01,\n",
       "   351.96,\n",
       "   338.73,\n",
       "   355.32,\n",
       "   345.08,\n",
       "   354.95,\n",
       "   346.21,\n",
       "   350.09,\n",
       "   346.21,\n",
       "   341.86,\n",
       "   346.21,\n",
       "   341.11,\n",
       "   345.46,\n",
       "   343.73,\n",
       "   334.24,\n",
       "   344.85,\n",
       "   319.65,\n",
       "   344.48,\n",
       "   313.3,\n",
       "   343.73,\n",
       "   326.01,\n",
       "   341.86,\n",
       "   340.6,\n",
       "   339.62,\n",
       "   348.82,\n",
       "   341.49,\n",
       "   352.94,\n",
       "   344.1,\n",
       "   355.56,\n",
       "   343.36,\n",
       "   357.42,\n",
       "   341.11,\n",
       "   357.8,\n",
       "   338.49,\n",
       "   359.67,\n",
       "   336.25,\n",
       "   360.79,\n",
       "   334.75,\n",
       "   360.79,\n",
       "   331.01,\n",
       "   360.79,\n",
       "   328.77,\n",
       "   359.67,\n",
       "   327.27,\n",
       "   356.68,\n",
       "   329.14,\n",
       "   354.43,\n",
       "   329.14,\n",
       "   352.56,\n",
       "   328.02,\n",
       "   351.44,\n",
       "   328.77,\n",
       "   348.45,\n",
       "   328.77,\n",
       "   344.34,\n",
       "   329.14,\n",
       "   340.6,\n",
       "   329.89,\n",
       "   334.24,\n",
       "   329.52,\n",
       "   325.26,\n",
       "   328.77,\n",
       "   323.39,\n",
       "   325.03,\n",
       "   326.01,\n",
       "   322.04,\n",
       "   324.52,\n",
       "   319.05,\n",
       "   322.27,\n",
       "   320.17,\n",
       "   334.24,\n",
       "   319.8,\n",
       "   343.96,\n",
       "   319.8,\n",
       "   352.94,\n",
       "   319.42,\n",
       "   354.06,\n",
       "   311.19,\n",
       "   352.94,\n",
       "   308.2,\n",
       "   352.94,\n",
       "   304.84,\n",
       "   353.69,\n",
       "   304.09,\n",
       "   351.07,\n",
       "   306.71,\n",
       "   347.33,\n",
       "   309.7,\n",
       "   344.71,\n",
       "   309.7,\n",
       "   343.21,\n",
       "   307.45,\n",
       "   332.74,\n",
       "   307.08,\n",
       "   330.87,\n",
       "   305.21,\n",
       "   325.64,\n",
       "   305.21,\n",
       "   320.4,\n",
       "   304.09,\n",
       "   313.67,\n",
       "   303.34,\n",
       "   310.3,\n",
       "   303.34,\n",
       "   305.82,\n",
       "   302.97,\n",
       "   299.46,\n",
       "   303.34,\n",
       "   296.84,\n",
       "   301.84,\n",
       "   294.22,\n",
       "   301.1,\n",
       "   290.86,\n",
       "   301.1,\n",
       "   287.87,\n",
       "   299.6,\n",
       "   285.62,\n",
       "   297.73,\n",
       "   277.4,\n",
       "   300.72,\n",
       "   271.04,\n",
       "   304.46,\n",
       "   266.55]],\n",
       " 'area': 4290.290900000001,\n",
       " 'iscrowd': 0,\n",
       " 'image_id': 329219,\n",
       " 'bbox': [297.73, 252.34, 60.21, 108.45],\n",
       " 'category_id': 18,\n",
       " 'id': 8032}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance[\"annotations\"][10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eopsn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
